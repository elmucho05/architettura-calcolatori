### Il processore

*note dal libro*

Le prestazioni di un calcolatore sono determinate da tre fattori:

1. *numero istruzioni*

2. durata del ciclo di clock

3. durata del ciclo di clock per istruzione (cpi)

In questo capitolo si costruisce ununità di elaborazione dati *datapath* e un unità di controllo *controll unit* associata a due differenti impelmentazioni hardware delle istruzioni riscv.

In particolare, il capitolo fornisce una spiegazione dei principi e tecninche adottate nella costruzione di un processore, partendo da una visione semplificata. Poi si descrive un'implementazione basta sulla **pipeline**. 

**Un implementazione di base del RiscV**

esamineremo u'implemeentazione che comprende il seguente sottoinsieme di istruzioni  di base del risc-v:

- le istruzion di riferimento alla memoria *load doubleword* **ld**, e *store doubleword* **sd**

- le istruzioni aritmetico-logiche *add, sub, and,or*

- le istruzioni di salto icondizionato dal risultato di un test di uguaglianza, *beq, branch equals*

Nei capitoli precedenti abbiamo visto le istruzioni di base RISC-V. Per realizzare ogni istruzione i primi due passi sono gli stessi:

1. inviare il contenuto del programm counter (PC) alla memoria che contiene il programma e prelevaare l'istruzione dalla memoria. Questa operazione viene anche indicata anche col termine *fetch* che significa *raggiungere*.

2. Leggere il contenuto di uno o due registri usando i campi dell'istruzione per selezionare i registri. (*decode*)

Dopo questi due passi, le azioni richieste per completare l'esecuzione delle istruzioni dipendono dalla loro *tipologia*.  Fortunamenamente, per ognuna delle 3 classi(istruzioni di accesso alla memoria, aritemtico-logiche e di salto), le azioni da coompiere sono, a grandi linee, le stesse, indipendentemente dal particolare *opcode* dell'istruzione. 

*(execute)*

Per esempio, tutti i tipi di istruzioni, eccetto i salti incondizionati, usando l'unità *aritmetico-logica* (ALU) dopo aver letto i registri. 

- Le istruzioni di accesso alla memoria utilizzano la ALU per il calcolo dell'indirizzo.

- Le istruzioni aritmetico-logiche usano la ALU per per l'esecuizione della loro operazione

- i salti *condizionati* usano la ALU per effettuare confronti. 

**Dopo aver usato la ALU** le azioni richieste per completare l'esecuzione dell'istruzione, variano a seconda del tipo di istruzione:

- istruzioni di acesso alla memoria hanno bisogno di accedere alla memoria sia per scrivere che per leggere i dati (*memory*)

- l'istruzione di tipo aritmetico-logica, dovrà invece scrivere i dati prodotti dalla ALU in un *registro destinazione.*

- in un istruzione di salto condizionato, l'indirizzo all'istruzione successiva può cambiare in base al risulatato del confronto, per esempio, in assenza il PC veràà incrementato di 4 per puntare ad un'istruzione successiva. (writeback)

Il seguente schema è una versione semplificata di com'è fatto l'hardware che esegue le istruzione seguente lo schema di sopra:

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-17-15-11-51-image.png)

(schema slide 6)

Il PC mi dice dove si trova dentro la INSTRUCTION MEMORY l'istruzione che devono andare a recuperare. Dò in input un indirizzo e tiro fuori 32 bit di istruzione.

Nella fase successiva è quella di *decode*, decodfico l'istruzione determinare quali registri tirare dal Register file, quindi registri destinazione, sorgente per passarli alla fase di *execute.*

Fase di execute, dove la alu fa le operazioni che deve a seconda del tipo di istruzione. Gli operandi di questa fase possono arrivare o dal Register file oppure dall'istruzione nel caso stiamo parlando di immediati.

Fase di memory: accediamo alla data memory passando un inidirizzo che è il risultato del calcolo fatto sulla alu, e anche un dato se sto facendo una store.

Alla load non serve il campo dato perché lo prelevo dalla memoria.

La fase di writeback torna a insistere sul register file. Se fosse un'istruzione di load, il dato da caricare lo prederei dalla memoria e lo metterei nel register file. Se fosse una R-instrucion tipo una add, il risultato che sarebbe portato sul register file sarebbe l'output della alu.

i due possibili di percorsi di write back sono due

1. dalla memoria al register file

2. dalla alu al register file

Per quanto riguarda l'incremendo del PC, abbiamo un adder che aggiunge +4 ne caso devo saltare alla prossima istruzione. 

Sennò prende il valore del pc e ci somma qualcosa che viene dall'istruzione, cioè l'immediato, per esempio nel caso di una branch. 

Entrambi i risultato ritornano al programm counter.

Abbiamo parlato di memory ma abbiamo anche differenziato la memoria in  memoria istruzioni e dati.

La memoria è la DRAM, quindi questa differenza è logica. 

Nella realtà, una cpu moderna assomiglia alla macchina di Von Neumann. 

In un sistema multicore, con due cpu, ciascuna cpu ha una cache di primo livello Instruction e Dati. Poi c'è una cache di secondo livello unificata e poi una cache di terzo livello ancora unificata. All'interno di un calcolatore moderno si trova un mix tra Harvard e Von Neuman. Più vicino alla cpu, per performance, devo dividere la memoria in memoria di istruzioni e dati. *Questo perché nello stesso ciclo vogliamo che la cpu sappia fare la fetch di un'istruzione e allo stesso tempo la load o store relativa ad un'altra istruzione*.

La nostra CPU quindi ha due memorie Istruzioni, che serve per il fetch e Dati, che serve per memorizzare dati.

*quello che abbiamo visto fin'ora è un datapath* poiché l'istruzione letteralmente scorre attraverso tutti quegli stadi. 

Però abbiamo visto che per controllare il comportamento  corretto di questo datapath serve della logica che fa controllo. 

Il problema è che abbiamo dei casi come in quelli di prima dove io so quale dato mandare per prima. Nell'esempio precedente che riporto qua:

La fase di writeback torna a insistere sul register file. Se fosse un'istruzione di load, il dato da caricare lo prederei dalla memoria e lo metterei nel register file. Se fosse una R-instrucion tipo una add, il risultato che sarebbe portato sul register file sarebbe l'output della alu.

i due possibili di percorsi di write back sono due

1. dalla memoria al register file

2. dalla alu al register file 

Sul *register file* non saprei quale dei due segnali far arrivare, perciò dovrei usare un multiplexer e un segnale di controllo che lo governa.

slide 16

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-17-15-51-07-image.png)

Devo aggiungere sia il multiplexer che i segnali di controllo che li pilotano. 

Per esempio, se è un'istruzione di brach, devo dire al multiplexer di far passare il valore di programm counter a destra e non quello che va all'istruzione successiva aggiungendo +4.

Devo anche configurare la data memory, che prende due segnali in ingresso in base a se sto facendo una load o una store. 

**Convenzioni del progetto logico**

La logica combinatoria è quella che ha un output che dipende solo dai valori degli ingressi in quel momento

La logica sequenziale è quella che ha memoria del suo passato.

**Come funzionano i registri**

I registri sono dispositivi sensibili al fornte di salita del *clock*, sono **edge triggered**, lavorano sul fronte di salita.

Oltre ad un segnale di clock , c'è un segnale di WriteEnable che serve a sincronizzare quando scrivo o no in memoria.

Da ricordare anche che un ciclo di clock più ampio, ci permette di fare più cose dentro un solo ciclo, ma riduce la nostra frequenza. Ciò che determina la minima larghezza, è il percorso critico tra due registri. Il ritardo di propagazione è quello che determina il periodo di clock.

### Creazione di un datapath

utilizzeremo registri, alu ed altro.

##### Fase di fetch

La prima parte è quella delle **instruction fetch**

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-16-22-23-image.png)

Tutte le istruzioni usano l'instruction fetch. 

Abbiamo quindi che ci serve il PC a 64, ci serve un'instrction Memory che è pilotata dall'indirizzo trovato dentro il program counter e che tira fuori i 32 bit di istruzione. 

In più, abbiamo anche la logica di incremento sequenziale del nostro PC, è l'adder che sta sopra. 

L'adder forma un loop se vedi perché è lui che aggiorna l'indirizz del program counter. La fase di fetch è dove attacco la logica di decodifica dell'istruzione e quindi alla prossima fase.

##### Fase decode

La fase di decodifica delle istruzioni è la seconda fase e varia a seconda del tipo di istruzione.

**R format instructions**

`add x9, x20,x21`

Abbiamo due registri sorgente e uno destinazione. Dobbiamo configurare la nostra ALU per fare un'operazione di tipo aritmetico-logico. 

E' anche un tipo di istruzione che usa il percorso di writeback perché riscrive il risultato del suo calcolo nel register file .

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-16-31-40-image.png)

Ognuna delle porte ha 5 fili per poter indirizziare tutti i 2^5=32 bit.

Ho anche un segnare di RegisterWrite e le 2 uscite che vanno alla alu e quindi fasi successive.

Nella ALU in questa fase, mi interessa solo il risultato e non il bit zero che mi dice solo se il risultato è zero.

RIassumendo : faccio la decode sul register file, uso la alu per calcoalre il risultato dell'operazione e poi con writeback torno a scrivere sul register file.

**Load/Store Instructions**

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-16-35-46-image.png)

C'è sì la prima parte, ma si aggiunge anche la parte di Load/Store unit.

Devo utilizzare anche la Memoria perché ci devo andare a leggere e scrivere, ma anche una *immediate generation unit* , che prende il campo immediato che è diverso nel caso di una load e diverso per una store, lo riordina nella maniera opportuna e dopodiché, lo trasforma in un registro a 64bit. Questo perché il nostro immediato diventa un operando per la ALU, la quale lavora solo a 64bit.

Nel caso della load/store `ld x5, 40(x6)`

x6 è il base address, il numero 40 arriva dall'istruzione. Prendo tutti i bit dell'immediato, fa la sign extension trasformandolo in un registro a 64bit. Questo viene  passato alla ALU come secondo operando. 

La ALU poi manderà questo risultato alla porta *address* della memoria. Si usa il segnale *memread* . Quello che leggo dall'uscita della memoria, viene mandata nella fase di writeback al register file.

Nel caso della store `sd x5, 40(x6)` 

La parte di imm gen calcola l'imediato e lo da in ingresso alla alu.  L'output della alu deve pilotare la parte indirizzo. Si imposta il bit di controllo memwirte a 1. La porta Read data2 viene pilotata dalla valore del registro dove voglio andare a scrivere. NON HO UNO STATO DI WRITE BACK PERCHE' NON devo scrivere  sul register file, quindi l'uscita da Data Memory è a 0.

##### Branch Instructions

per le branch instructions come `beq rs1, rs2, L1`

Leggo gli operandi, quindi i registri. **Per** **paragonare** i due operandi, uso la ALU. La **ALU** configurata in **modalità subtract e controllo il flag di controllo Zero**

Per calcolare il prossimo PC

- devo inanzitutto la sign extension, quindi la Immediate Generation Unit, che prende gli immediati e li riodina,  dopodiché fa la sign extension a 64bit

- shift a sinistra di una posizione

- solo alla fine può essere aggiunto al valore del PC attuale.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-18-49-42-image.png)

- L'istruzione entra dalla quale posso estrarre rs1 e rs2 che vengono passati a ImmediatGenerationUnit
  
  - che trasforma in 64bit con sign extension

- la ImmGenUnit passa il registro a 64bit allo shift a sinistra di 1 che si mette davanti alla logica di add che prende come operando il PC corrent e il risultato è il target del nostro branch.

- La ALU ha come output il bit Zero che è usato per la logica  

L'output dell'add viene passato poi al multiplexer del PC.

Questa seconda ALU fa parte della fase di execute.

Riassumendo, ogni elemento del datapath può solo fare una funzione alla volta, di conseguenza, dobbiamo separare l'istruzione e le data memories.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-19-06-44-image.png)

Notiamo che abbiamo una porta WriteRegister che identifica il registro dove andare a scrive, e la prota WriteData dove piloto il dato, la porta avrà grandezza 64, e viene fuori dai multiplexer che escono dalla alu oppure all'interfaccia di memoria ecco perché i 64bit. 

I vari segnali di controllo

- ALUSrc : può essere o una porta del register file o l'uscita della IMmediateGenUnit.

- ALU Operation: pilota la alu,, è un segnale di 4 bit per rappresentare tutte le possibili configurazioni della alu, quindi 2^4. 

- PCSrc : se prendo il classico PC di +4 o quello fatta dalla logica di add di una brach

- MemWrite e MemRead : se sto accedendo alla data Memory in modalità scrittura o lettura

- Mem2Reg : dalla memria al register file, mi dice se sto srivendo dalla memoria quindi una load, o quello che viene dalla alu. 

- Regwrite : allora il dato in ingresso da write data, lo scrivo in Write Register

questo è spiegato anche in questa immagine

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-19-14-37-image.png)

**Come facciamo a derivare questi segnali di controllo?**

Determiniamo questi segnali a paritre dalle istruzioni.

Ci sono vari livelli multipli gerarcici di decodifica-

1. Interviene per prima la **MCU**, Main Control Unit, che ha altri pezzi di logica ma sopratutto la ALU CONTROL. Dalla MCU vengono fuori vari segnali di controllo come quelli prima e soprattuto i segnale bit ALUOp che pilota la ALU CONTROL
   
   1. ALU CONTROL: decide come configurare la ALU per quella determinata istruzione.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-19-19-00-image.png)

La **MCU** usa i campi *opcode, func3 e func7*. Sapendo come sono fatte le istruzioni, riusciamo a capire quali sono istruzioni di memoria e quali di calcolo da com'è fatta l'istruzione. 

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-19-20-56-image.png)

Abbiamo il discroso di 12 bit di dato per l'offest dove bisogna andare a discriminare in base al tipo di istruzione.

Partendo da quelle info, la MCU è una rete combinatore per la quale a seconda del tipo di istruzione, posso subito determinare la maggior parte di controllo.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-19-22-22-image.png)

Per esempio se determino dall'opcode di che tipo di istruzione ho, trovo subito i lvalroe di ALUSrc.

Mem2Reg sono operazioni che hanno una fase di writeback

RegisterWrite : se ho bisogno di srivere sul register file, quindi tipo R e per le load

MemoryRead: load

MemoryWrite : store

Branch : per istruzioni branch

Determino in fondo, le due colonne ALUOp1 e ALUOp0 che è **l'ingresso della ALU control unit.**

Questi due bit ci servono per pilotare la ALU control che ci serve per fare fino a 16 operazioni diverse, noi guardiamo solo add, sub, and, or.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-19-27-26-image.png)

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-19-27-56-image.png)

I bit di ALUOp si scelgono per vari motivi, tipo per semplicità. In questo caso, una volta che ho determinato i bit di alu op, si fa una tabella di verità che va a vedere i campi *func3* e *func7* per capire di che tipo di istruzione si calcola.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-18-19-30-54-image.png)

##### Datapath nel caso di un'operazione di add (R-type)

`add x9, x20,x21`

Nella fase di decode, tutti icampi entranti nei registri sono validi. Il wirte register è l'indirizzo dove scrivere e register1 e register2 sono x20 e x21.

## Instruction Level-Parallelism

Studiamo il parallelismo a livello di singola istruzione. Come possiamo sfruttare il parallelismo mandando in esecuzione più istruzioni alla volta .

Vedremo anche un'altra forma di parallelismo che è quello tra thread *il progetto di CPU multicore* 

Ci rendiamo conto che le operazioni da svolgere per eseguire le istruzioni, sono classificate in step

- step che si possono dividere in stadi della notra catena di montaggio. Stadi che sono realizzati tramite blocchi hardware che possono eseguire in parallelo.

L'idea quindi di spezzare in 5 fasi la nostra esecuzione, mi permette di avere 5 istruzioni che stanno eseguendo.

*Cosa possiamo fare per incrementare il parallelismo?*

A livello di programma in**tero, lo speedup ideale è pari alla profondità della pipeline.**

- Proviamo a rendere le pipeline più profonde, quindi cn più stadi. Questo significa partiizonare in blocchi più piccoli il lavoro fatto in ogni stato. Questo equivale a ridurre il cammino critico nel caso peggiore. *così si ha un ciclo di clock più corto e quindi frequenza migliroe*
  
  - esiste però un limite a questa idea, perché ad un certo punto devo comunque aggiungere tanta logica. ci sono già meccanismi come quello delle *hazard detection e branch speculation*. 

Un'altra maniera nel single core, è quella di **replicare alcuni stadi delle pipeline** creando quelli che sono Multiple Issue processors

- processori che in un ciclo di clock, riescono a completare l'esecuzione di più istruzioni

- questo significa che devo replicare i blocchi logici e quindi avrò un CPI < 1.
  
  - con un processore di 4ghz che ha una multiple issue a 4 vie, quindi è in grado di ritirare per ogni ciclo 4 istruzioni, ho un CPI di picco di 0,25 e una IPC = 4.

- ma nella pratica, la dipendenza fra i dati, riduce questo miglioramento.

#### Multiple Issue

CI sono due maniere di realizzarlo

1. **multiple issue statico** : quando compiliamo il programma, andiamo a studiare le istruzioni e vedere che dipendenze ci sono tra l'uso dei registri. è il compilatore che capisce dove ci sono dipendenze, e li impacchetta dentro questi *slots* di istruzioni che possono essere mandate sulle varie pipeline/datapath . Quindi la detection e l'evitare i data hazard è fatta in modo statico a tempo di compilazione.

2. **multiple issue dinamico** : questo controllo avviene mentre esegue. La cpu ha una logica che esamina questo stream di istruzioni e sceglie quale eseguire. Quali hanno una dipendenza e devono stare in stallo e quali devono eseguire. 
   
   1. Quello che non si sà a compile time, come con i puntatori dei quali non sai gli indirizzi, l'approccio dinamico mi permette di continuare la **speculazione**

**speculation**

Indovino cosa averrà nel programma durante la sua esecuzione. Voglio schedulare questa istruzione il prima possibile. Se devo aspettare che la dipendeza venga risolta, perderei performance. 

 La *speculation* usa un approccio ottimistico. Quando sono in grado di stabilire la correttezza dell'ipotesi, posso completare l'operazione (cioè mettere gli effetti sullo stato del sistema, quindi memoria e rf).

sennoò devo fare *rollback* e quindi cancellare gli effetti temporali dell'istruzione. COme nelle branch o delle load speculative(load che dipende da istruzioni non ancora finite, quindi provo a speculare l'indirizzo dove scriverà la load. Speculo sulla memoria del programma, su una cache e sul valore del PC).

Quindi il *compilatore può riordinare le istruzioni*, e può anche verificare se le speculations erano corrette.

- **può aggiungere** delle istruzioni: sposta le istruzioni che voleva eseguire speculativamente e poi aggiunge del codice che dice "qual è stato l'esito, se era corretto, vado avanti".

Dopodiché ha  dei buffer, all'interno dei quali pubblica temporaneamente il risultato delle op che esegue in maniera speculativa. Se era scorretta lo svuoto, se era corretta, le cose del buffer le scrivo nello stato del sistema.

**Speculations and Exceptions**

Se una eccezione accada in una istruzione eseguita speculativamente, allora devo essere in grado di gestire il problema (load speculativa, eseguita perima della verifica del puntatore nullo).

*speculazione statica*

posso agigungere un'istruzione dedicata che permette di spostare più in là l'esecuzione delle eccezioni perché devo sapere l'esito 

*dinamico*

bufferizzo le mie eccezzioni finché l'istruzione è completata.

##### Static Multiple issue

Il compilatore raggruppa le istruzioni in *issue packets* che sono gruppi di istruzioni che possono essere  issued in un singolo ciclo.

- sono determinate dalle risorse delle pipeline richieste.

Li istruzion sono messe i coppie che non devono essere dipenendenti. Questo si chiama **issue packets**.

Pensare ad una *issue packet* come una istruzione molto lunga. Specifica multiple concurrent operations

Se non riesco a schedulare il programma con delle istruzioni che occupano tutte le istruzioni, sennò ci metto una *nop*

Una classica suddivisione delle tipologie di istruzioni per un Dual Issue sono

- uno che raggruppa le istruzioni alu/branch

- e uno che raggruppa load/store

Una double issue usa 64bit, quindi una *very long* instruction word.

Nel tempo,come funziona l'esecuzione ideale di questa maniera di schedulare le istruzioni:

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-13-54-23-image.png)

Faccio scheduling di modo che posso avere una pipeline ordinata mettendo quel tipo di istruzioni ad quelli offset, tipo n+4 o n+6, so che ci metterò quel tipo di istruzione.

Per poterlo fare, devo replicare la ALU, le porte di accesso al register file, immediate generation, rendere più grande la parte di instrction memory, i passi di writeback.

La problematica degli hazard ci limita nella capacità di usare il dual/multiple issue perché il forwarding ci evita completamente lo stallo. 

issue execute

Qua non posso mettere nello stesso blocco due istructions una dopo l'altra, qua devo spezzettarle e usano solo metà della mia very long word.

issue load use

avrò sempre un ciclo di latenza, ma ora ho due istruzioni, devo avere politiche più aggressive.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-19-24-10-image.png)

Dobbiamo schedularlo per un loop dual isue.

Ha due slot, per le alu/branch e per le dual issue.

Ho tutta una serie di dipendenze, lo scheduling è abbastanza complicato. 

Schedulo in ANTICIPO le add e addi, di modo che posso alla fine schedulare la branch insieme alla store double.

- una delle due istruzioni da mettere deve essere per forza una load o store
  
  - quindi la prossima che dovrei caricare è la *sd* ma non posso caricare direttamente la sd e poi una add perché avrei un hazard
    
    - cerco quindi di **schedulare le operazioni** con dipendenza prima della store
    
    - metto quindi la addi, e noto che la store dipende da x31 che è cambiato nella add
    
    - schedulo quindi : addi,add, blt e poi la sd
      
      - la Store va modificata perché avendo decrementato a -8 con addi, devo aggiungere all store un offset di 8

Sto scrivendo 5 istruzioni su 4 cicli di clock. Quindi avrò un ICP di $\frac {5}{4}=1,25$

###### Loop Unrolling

è una tecnica che uso per mostrare il parallelismo nel mio programma. Nella maggior parte dei casi, il lavoro che c'è nel loop è indipendente dalle prossime iterazioni.

E' l'espansione di un numero delle iterazioni del loop per rendere più visibile più parallelismo a livello di istruzione.

Bisogna fare attenzione ad alcune cose:

- **register renaming** creare registri in modo corretto senza avere dipendenze.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-19-43-05-image.png)

Se srotolo di un fattore 4, il loop avrà 4 delle vecchie istanze dentro ad una singola iterazione del loop. Quindi in una sola iterazione del loop, faccio il lavoro di 4.

Il loop alla fine, mi sposta il puntatore finale non di 8, ma di 32, cioè 8*4.

Vanno aggiornate anche le  store e le load con i loro offest.

Devo fare renaming dei registri per non creare dipendenze.

 Il vantaggio di fare questa cosa è che ora ho molte più istruzioni che posso mettere negli slot doppi.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-19-46-33-image.png)

Ho un IPC migliore. Questa però è stato fatta a costo di maggiore uso della risorsa registro e un eseguibile più grande, ho 14 istruzioni ora.

**Dynamic Multiple Issue**

I processori che lavorano così si chiamano *multiscalari*. Questo schema permette di decidere quali istruzione eseguire in un dato ciclo di clock e allo stesso tempo di evitare hazard e stalli. 

Questo permette di non fare scheduling a livello di compilatore ma potrebbe comunque servire.

**scheduling pipeline dinamico**

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-19-52-26-image.png)

Questo contiene degli hazrd sui dati. 

Anche se l'istruzione *sub* è prionta per essere eseguita, deve aspettare che l'esecuzione della *ld* e *add* sia completata. 

Nella riorganizazzione dinamica del codice si sceglie quali istruzioni eseguire nei cicli di clock successivi, eventualmente riordinandole in modo da evitare stalli.

La pipeline viene suddivisa in tre unità principali :

1. unità che preleva l'istruzione dalla memoria e la avvia all'esecuzione

2. un gruppo di più unità funzionali

3. **un'unità di consegna**

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-19-57-36-image.png)

La prima unità preleva le istruzioni, le codifica e invia ciascuna di esse alla corrispondente unità funzionale per l'esecuzione. 

Ciascuna unità funzionale ha dei *buffer*, chiamati **stazioni di prenotazione(*reservation stations*)** che conservano gli operandi e l'operazione.

Non appena la stazione di prenotazione contiene tutti gli operandi richieste e l'unità funzionale è pronta per l'esecuzione, viene eseguita l'operazione e inviato il risultato alle stazioni di prenotazione che lo stanno attendendo e anche all'unità di consegna.

Quest'ultima conserva il risultato dell'operazione fino a quando non avrà via libera per salvarlo nel register file o, ne l caso di store, nella memoria. 

Il buffer presente nell'unita di consegna è chiamato **reorder buffer** e viene usato per per fornire gli operandi, un pò come faceva la logica di propoagazione. Una volta scritto il risultato nel register file, esso può essere prelevato da lì come in una normale pipeline.

***Register Renaming per la dynamic***

c'è bisogno di implementare il register renaming, sennò sarei troppo concentrato a vedere solo i nomi dei registri, a questo ci pensano il reorder buffer e le reservation station. 

Quando un'istruzione viene fetchata e mandata alla reservation station

- se l'operando è disponibile nel register file o reorder buffer
  
  - viene copiato sulla reservation station
  
  - non serve più dentro al registro il quale può essere sovrascritto

- se l'operando non è disponibile nel register file o reorder buffer
  
  - sarà mandato alla reservation station da una unità funzionali
  
  - e potremmo non avere bisogno di aggiornare il registro

**Speculation**

Posso fare una predizione del branch, del target address e quindi mandare in esecuzione le istruzioni, perché posso ritardare il momento in cui posso fare il commit. 

Prima , dovevo aspettare prima di applicare lo stato modificato, dovevo verificare se la speculation non fosse sbagliata

- in questo caso abbiamo delle unità che mi danno l'ok e devo solo aspettare l'ok
  
  - se ho sbagliato, allora il risultato nella commit unit viene scartato
  
  - devo istruire le reservation station che devo ripetere l'istruzione

- *load speculation* : posso evitare il delay associato alle load e alle cache miss, facendo la prediction dell'indirizzo, del valore caricato. Così posso anche bypassare le cose in store e le metto nella load unit.

Posso quindi bypassare anche la dipendenza fra le load e store.

Non potrò completare il commit della load finché non posso sapere l'esito della mia speculation.

##### Potenza e consumi

$Power = Capacitiveload \times Voltage^2 \times Frequency$

Per evitare consumo di potenza da un nodo teconologico all'altro, dal momento che ho un raddoppio di transistor nel mio chip, devo garantire che ci sia uno scaling anche nel consumo individuale

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-20-20-26-image.png)

Mi porta che ho un rapporto di circa metà, 0.52. Arrivo però ad un punto in cui c'è una problematica per cui c'è densità di corrente su un'area più piccola che genera calore che non sono in grado di dissipare calore.

C'è un valore di soglia della tensione di alimentazione che dà un margine a quanto possiamo scegliere.

Col passare del tempo non uso cpu singola più potenti , ma ne uso molte. Uso più di un processore per cpu. 

Sulla carta, mettere più CPU può portare a una performance di picco pari alla CPU.

Per la legge di moore, ho sempre più transistor, quelli li uso per creare altre istanze della mia CPU. 

- però questo richiede programmazione parallela.

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-20-25-50-image.png)

La frequenza, la performance single thread rimangono fisse.

uso come paradigma di design quello del multicore, per essere sicuro che la performance cresca , devo garantire che tra le operazioni ci sia parallelismo.

Un problema che è quello più evidente è quello legato alla legge di Amdahl:

per quanto io abbia tanti core, i programmi difficilmente hanno 100% parallelismo, ci sono delle parti di controllo che sono difficilmente parallelizzabili.

La quantità di miglioramente è vincolata alla quantità di istruzioni che posso parallelizzare/fattore di miglioramente (numero di processori nel mio caso):

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-20-29-30-image.png)

![](/home/gerti/.var/app/com.github.marktext.marktext/config/marktext/images/2024-05-20-20-31-47-image.png)
